{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Basic Functionality\n",
    "This NoteBook covers the most common functions and provides you with code snippets to begin with\n",
    "\n",
    "â“˜ Issues running locally? Read our new [local setup guide](https://github.com/KillianLucas/open-interpreter/blob/main/GPU.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import interpreter\n",
    "\n",
    "# Skip confirmation before any code excecution by enabling auto_run\n",
    "interpreter.auto_run = True\n",
    "\n",
    "# Chose your model from the list: ['code-llama', 'gpt-3.5-turbo', 'gpt-4']\n",
    "interpreter.model = \"gpt-3.5-turbo\"\n",
    "\n",
    "# Set your temperature. 0.0 is the most conservative, 1.0 is the most creative.\n",
    "interpreter.temperature = 0\n",
    "\n",
    "# Paste your OpenAI API key below.\n",
    "interpreter.api_key = \"your_openai_api_key\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Write a Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by asking the interpreter to print Hello World."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use method `chat(\"[Your Command Here]\")` to send your command to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.chat(\"Please print hello world.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Start a new Chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your model remembers your previous messages unless you specifically refresh your dialogue with `reset()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ! Remember, each time you send a request to a model, all your history is sent to OpenAI API, meaning the number of tokens increases with each new prompt you type if you don't clear the history.\n",
    "\n",
    "**Note:** The command-line version of Open Interpreter resets itself automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.reset()\n",
    "interpreter.chat(\"Can you solve this equation? 10x + 14 = 21 / 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Activate interactive Chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can activate interactive chat in the terminal if you don't pass any arguments to `chat()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask it a question, i.e. \"What are the last 10 BBC news headlines?\"\n",
    "\n",
    "Then type \"exit\" to close the interactive chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save and Load dialogue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can save messages and load them into the dialogue to start with the same initial conditions again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save messages to 'messages'\n",
    "messages = interpreter.chat(\"My name is Killian.\", return_messages=True) \n",
    "\n",
    "# Reset interpreter (\"Killian\" will be forgotten)\n",
    "interpreter.reset() \n",
    "\n",
    "# Resume chat from 'messages' (\"Killian\" will be remembered)\n",
    "interpreter.load(messages) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Customize System Message\n",
    "\n",
    "Put a system message in the model to configure it the behaviour of the model throughout the whole dialogue.\n",
    "\n",
    "Use it to extend functionality, modify permissions, or give it more context. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.system_message += \"\"\"\n",
    "Run shell commands with -y so the user doesn't have to confirm them.\n",
    "\"\"\"\n",
    "print(interpreter.system_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Change the model\n",
    "\n",
    "You can select the local model in CLI:\n",
    "- `interpreter --local` -> uses Code Llama\n",
    "- `interpreter --fast` -> uses gpt-3.5-turbo\n",
    "\n",
    "In Python you select the model as follows\n",
    "```python\n",
    "interpreter.model = \"gpt-3.5-turbo\"\n",
    "```\n",
    "List of available models: `['code-llama', 'gpt-3.5-turbo', 'gpt-4']`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Azure Support\n",
    "\n",
    "To connect to an Azure deployment, the `--use-azure` flag will walk you through setting this up:\n",
    "\n",
    "`interpreter --use-azure`\n",
    "\n",
    "In Python, set the following variables:\n",
    "```python\n",
    "interpreter.use_azure = True\n",
    "interpreter.api_key = \"your_openai_api_key\"\n",
    "interpreter.azure_api_base = \"your_azure_api_base\"\n",
    "interpreter.azure_api_version = \"your_azure_api_version\"\n",
    "interpreter.azure_deployment_name = \"your_azure_deployment_name\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Debug Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help contributors inspect Open Interpreter, `--debug` mode is highly verbose.\n",
    "\n",
    "You can activate debug mode by using it's flag (interpreter `--debug`), or mid-chat:\n",
    "\n",
    "```bash\n",
    "$ interpreter\n",
    "...\n",
    "> %debug # <- Turns on debug mode\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open_int",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
