# Set to 'True' or 'False' to determine if the code should execute without user confirmation
INTERPRETER_CLI_AUTO_RUN=False

# Set to 'True' or 'False' to determine if gpt-3.5-turbo should be used instead of gpt-4
INTERPRETER_CLI_FAST_MODE=False

# Set to 'True' or 'False' to determine if the code should run fully local with code-llama
INTERPRETER_CLI_LOCAL_RUN=False

# Set to 'True' or 'False' to enable or disable debug mode
INTERPRETER_CLI_DEBUG=False

# Set to 'True' or 'False' to determine if Azure OpenAI Services should be used
INTERPRETER_CLI_USE_AZURE=False

# Only uncomment below three options if you want to use local mode

# Model count options: 7B, 13B, 34B
# INTERPRETER_LOCAL_MODEL_COUNT=7B 

# Model quality options: Low, Medium, High
# INTERPRETER_LOCAL_MODEL_QUALITY=Low 

# Set to 'True' or 'False' to determine if GPU should be used
# INTERPRETER_LOCAL_USE_GPU=False