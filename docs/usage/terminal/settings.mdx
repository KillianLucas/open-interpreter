---
title: Settings
---

Default settings can be edited via a configuration file. To open the file, run:

```bash
interpreter --config
```

The format for adding configurations is:
```yaml
key: Value
```

| Key                       | Value            |
|---------------------------|------------------|
| `custom_instructions`     | String `"Write your custom instruction"` |
| `system_message`          | String `"Write your custom system message"` |
| `auto_run`                | Boolean `True or False` |
| `verbose`                 | Boolean `True or False` |
| `max_output`              | Integer `2000`              |
| `force_task_completion`   | Boolean `True or False` |
| `disable_telemetry`       | Boolean `True or False` |
| `offline`                 | Boolean `True or False` |
| `speak_messages`          | Boolean `True or False` |
| `safe_mode`               | String `"off" or "ask" or "auto"`|
| `config_file`             | String `"path/config_name.yaml"`|
| `fast`                    | Boolean `True or False` |
| `local`                   | Boolean `True or False` |
| `vision`                  | Boolean `True or False` |
| `os`                      | Boolean `True or False` |

Parameters for LLMs:

| `llm.model`                   | String `"openai/model_name"` |
| `llm.api_base`                | String `"http://ip_address:port/v1" or "https://api.provider.example"` |
| `llm.api_key`                 | String `"sk-secret-key"` |
| `llm.api_version`             | String `"azure version"` |
| `llm.context_window`          | Integer `4000` |
| `llm.temperature`             | Float `0.0 to 1.0` |
| `llm.max_budget`              | Float `0.1` USD |
| `llm.max_tokens`              | Integer `4000` |
| `llm.llm_supports_functions`  | Boolean `True or False`  |
| `llm.llm_supports_vision`     | Boolean `True or False`  |